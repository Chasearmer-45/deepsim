Shape of X: torch.Size([32, 31])
Shape of y: torch.Size([32, 5]) torch.float32
Using cpu device
NeuralNetwork(
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=31, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=5, bias=True)
  )
)
Epoch 1
-------------------------------
train loss: 5388.485352  [    0/108727]
train loss: 49.260426  [ 3200/108727]
train loss: 17.920000  [ 6400/108727]
train loss: 23.086521  [ 9600/108727]
train loss: 9.546772  [12800/108727]
train loss: 6.195431  [16000/108727]
train loss: 9.576785  [19200/108727]
train loss: 8.475660  [22400/108727]
train loss: 5.752267  [25600/108727]
train loss: 5.368163  [28800/108727]
train loss: 5.547494  [32000/108727]
train loss: 6.282811  [35200/108727]
train loss: 9.406651  [38400/108727]
train loss: 5.104940  [41600/108727]
train loss: 11.312304  [44800/108727]
train loss: 4.503801  [48000/108727]
train loss: 7.900894  [51200/108727]
train loss: 8.537451  [54400/108727]
train loss: 7.562134  [57600/108727]
train loss: 10.050136  [60800/108727]
train loss: 7.316077  [64000/108727]
train loss: 14.250424  [67200/108727]
train loss: 5.382960  [70400/108727]
train loss: 7.700827  [73600/108727]
train loss: 7.431590  [76800/108727]
train loss: 4.413355  [80000/108727]
train loss: 11.227610  [83200/108727]
train loss: 5.558474  [86400/108727]
train loss: 10.458984  [89600/108727]
train loss: 3.530904  [92800/108727]
train loss: 4.453155  [96000/108727]
train loss: 3.923999  [99200/108727]
train loss: 10.432867  [102400/108727]
train loss: 10.589729  [105600/108727]
Avg validation loss: 5.658246
Avg out-of-distribution loss: 5.729552
Epoch 2
-------------------------------
train loss: 3.701900  [    0/108727]
train loss: 2.621870  [ 3200/108727]
train loss: 5.073449  [ 6400/108727]
train loss: 7.391125  [ 9600/108727]
train loss: 6.753160  [12800/108727]
train loss: 6.045857  [16000/108727]
train loss: 6.348533  [19200/108727]
train loss: 16.807280  [22400/108727]
train loss: 3.895246  [25600/108727]
train loss: 5.057261  [28800/108727]
train loss: 6.781301  [32000/108727]
train loss: 6.172093  [35200/108727]
train loss: 4.030951  [38400/108727]
train loss: 4.992986  [41600/108727]
train loss: 8.892332  [44800/108727]
train loss: 6.260129  [48000/108727]
train loss: 3.738102  [51200/108727]
train loss: 5.507880  [54400/108727]
train loss: 2.467641  [57600/108727]
train loss: 12.154001  [60800/108727]
train loss: 4.064641  [64000/108727]
train loss: 6.310365  [67200/108727]
train loss: 7.687448  [70400/108727]
train loss: 4.196819  [73600/108727]
train loss: 2.890620  [76800/108727]
train loss: 6.796685  [80000/108727]
train loss: 7.783867  [83200/108727]
train loss: 6.727254  [86400/108727]
train loss: 2.446330  [89600/108727]
train loss: 3.307885  [92800/108727]
train loss: 3.883067  [96000/108727]
train loss: 5.053921  [99200/108727]
train loss: 6.264979  [102400/108727]
train loss: 5.523193  [105600/108727]
Avg validation loss: 4.233454
Avg out-of-distribution loss: 4.430748
Epoch 3
-------------------------------
train loss: 2.157502  [    0/108727]
train loss: 3.600785  [ 3200/108727]
train loss: 5.208780  [ 6400/108727]
train loss: 5.372819  [ 9600/108727]
train loss: 3.252670  [12800/108727]
train loss: 10.541174  [16000/108727]
train loss: 3.217033  [19200/108727]
train loss: 6.170865  [22400/108727]
train loss: 8.417729  [25600/108727]
train loss: 3.815756  [28800/108727]
train loss: 5.230876  [32000/108727]
train loss: 3.195812  [35200/108727]
train loss: 2.913769  [38400/108727]
train loss: 11.769457  [41600/108727]
train loss: 3.235874  [44800/108727]
train loss: 6.785593  [48000/108727]
train loss: 3.585002  [51200/108727]
train loss: 3.712716  [54400/108727]
train loss: 4.364196  [57600/108727]
train loss: 3.748760  [60800/108727]
train loss: 2.212825  [64000/108727]
train loss: 4.644525  [67200/108727]
train loss: 3.993024  [70400/108727]
train loss: 4.659930  [73600/108727]
train loss: 2.777339  [76800/108727]
train loss: 5.599229  [80000/108727]
train loss: 3.619371  [83200/108727]
train loss: 2.223962  [86400/108727]
train loss: 3.849328  [89600/108727]
train loss: 6.433359  [92800/108727]
train loss: 3.502060  [96000/108727]
train loss: 3.669535  [99200/108727]
train loss: 4.600513  [102400/108727]
train loss: 2.877751  [105600/108727]
Avg validation loss: 3.636985
Avg out-of-distribution loss: 3.800387
Epoch 4
-------------------------------
train loss: 2.949998  [    0/108727]
train loss: 4.348197  [ 3200/108727]
train loss: 4.634814  [ 6400/108727]
train loss: 5.359746  [ 9600/108727]
train loss: 2.856617  [12800/108727]
train loss: 4.812829  [16000/108727]
train loss: 4.562114  [19200/108727]
train loss: 3.125226  [22400/108727]
train loss: 4.318668  [25600/108727]
train loss: 1.705613  [28800/108727]
train loss: 6.812660  [32000/108727]
train loss: 5.432815  [35200/108727]
train loss: 1.881479  [38400/108727]
train loss: 5.350965  [41600/108727]
train loss: 3.440193  [44800/108727]
train loss: 2.256483  [48000/108727]
train loss: 2.501175  [51200/108727]
train loss: 3.355658  [54400/108727]
train loss: 2.341246  [57600/108727]
train loss: 2.695743  [60800/108727]
train loss: 3.737624  [64000/108727]
train loss: 3.063159  [67200/108727]
train loss: 3.503129  [70400/108727]
train loss: 4.367895  [73600/108727]
train loss: 4.408737  [76800/108727]
train loss: 5.357755  [80000/108727]
train loss: 4.135469  [83200/108727]
train loss: 2.935674  [86400/108727]
train loss: 3.649019  [89600/108727]
train loss: 3.130822  [92800/108727]
train loss: 2.424270  [96000/108727]
train loss: 2.368882  [99200/108727]
train loss: 2.921098  [102400/108727]
train loss: 2.454617  [105600/108727]
Avg validation loss: 2.787765
Avg out-of-distribution loss: 3.005388
Epoch 5
-------------------------------
train loss: 1.555038  [    0/108727]
train loss: 1.221088  [ 3200/108727]
train loss: 3.318912  [ 6400/108727]
train loss: 1.794052  [ 9600/108727]
train loss: 2.253777  [12800/108727]
train loss: 1.805067  [16000/108727]
train loss: 2.993810  [19200/108727]
train loss: 4.101355  [22400/108727]
train loss: 1.953209  [25600/108727]
train loss: 2.907635  [28800/108727]
train loss: 2.361358  [32000/108727]
train loss: 3.070169  [35200/108727]
train loss: 2.780918  [38400/108727]
train loss: 1.993580  [41600/108727]
train loss: 1.788302  [44800/108727]
train loss: 3.200845  [48000/108727]
train loss: 2.775914  [51200/108727]
train loss: 2.472131  [54400/108727]
train loss: 4.901534  [57600/108727]
train loss: 1.730464  [60800/108727]
train loss: 3.924953  [64000/108727]
train loss: 2.755788  [67200/108727]
train loss: 2.567270  [70400/108727]
train loss: 3.080466  [73600/108727]
train loss: 1.575083  [76800/108727]
train loss: 6.360929  [80000/108727]
train loss: 3.262062  [83200/108727]
train loss: 2.114093  [86400/108727]
train loss: 1.743032  [89600/108727]
train loss: 3.748421  [92800/108727]
train loss: 3.426425  [96000/108727]
train loss: 2.316028  [99200/108727]
train loss: 2.555432  [102400/108727]
train loss: 3.846765  [105600/108727]
Avg validation loss: 2.931916
Avg out-of-distribution loss: 3.154720
Epoch 6
-------------------------------
train loss: 3.906130  [    0/108727]
train loss: 3.054936  [ 3200/108727]
train loss: 2.319112  [ 6400/108727]
train loss: 6.090572  [ 9600/108727]
train loss: 1.924607  [12800/108727]
train loss: 2.542987  [16000/108727]
train loss: 2.770602  [19200/108727]
train loss: 1.585130  [22400/108727]
train loss: 2.474591  [25600/108727]
train loss: 1.934907  [28800/108727]
train loss: 3.409935  [32000/108727]
train loss: 2.736058  [35200/108727]
train loss: 3.932245  [38400/108727]
train loss: 3.349628  [41600/108727]
train loss: 3.722063  [44800/108727]
train loss: 2.261621  [48000/108727]
train loss: 3.217931  [51200/108727]
train loss: 1.898504  [54400/108727]
train loss: 3.129717  [57600/108727]
train loss: 2.111587  [60800/108727]
train loss: 2.125277  [64000/108727]
train loss: 1.669716  [67200/108727]
train loss: 4.320747  [70400/108727]
train loss: 2.639053  [73600/108727]
train loss: 2.817055  [76800/108727]
train loss: 1.583322  [80000/108727]
train loss: 1.386989  [83200/108727]
train loss: 2.285292  [86400/108727]
train loss: 1.909917  [89600/108727]
train loss: 1.714739  [92800/108727]
train loss: 3.507238  [96000/108727]
train loss: 3.260457  [99200/108727]
train loss: 2.047243  [102400/108727]
train loss: 1.336870  [105600/108727]
Avg validation loss: 2.114923
Avg out-of-distribution loss: 2.330234
Epoch 7
-------------------------------
train loss: 1.612150  [    0/108727]
train loss: 2.137095  [ 3200/108727]
train loss: 1.435315  [ 6400/108727]
train loss: 1.646459  [ 9600/108727]
train loss: 1.498054  [12800/108727]
train loss: 3.921655  [16000/108727]
train loss: 1.909600  [19200/108727]
train loss: 1.828982  [22400/108727]
train loss: 2.289941  [25600/108727]
train loss: 2.438030  [28800/108727]
train loss: 1.322014  [32000/108727]
train loss: 3.080305  [35200/108727]
train loss: 1.482600  [38400/108727]
train loss: 2.208092  [41600/108727]
train loss: 1.440267  [44800/108727]
train loss: 3.127497  [48000/108727]
train loss: 1.216157  [51200/108727]
train loss: 3.043363  [54400/108727]
train loss: 2.915195  [57600/108727]
train loss: 2.958275  [60800/108727]
train loss: 2.038956  [64000/108727]
train loss: 1.839899  [67200/108727]
train loss: 1.640165  [70400/108727]
train loss: 1.837432  [73600/108727]
train loss: 2.101662  [76800/108727]
train loss: 2.510229  [80000/108727]
train loss: 2.174861  [83200/108727]
train loss: 2.012026  [86400/108727]
train loss: 1.065973  [89600/108727]
train loss: 1.685170  [92800/108727]
train loss: 2.257192  [96000/108727]
train loss: 2.265604  [99200/108727]
train loss: 2.436499  [102400/108727]
train loss: 3.761602  [105600/108727]
Avg validation loss: 2.018534
Avg out-of-distribution loss: 2.334014
Epoch 8
-------------------------------
train loss: 2.125753  [    0/108727]
train loss: 1.918473  [ 3200/108727]
train loss: 3.081910  [ 6400/108727]
train loss: 1.657047  [ 9600/108727]
train loss: 2.182292  [12800/108727]
train loss: 2.039787  [16000/108727]
train loss: 4.377324  [19200/108727]
train loss: 1.793413  [22400/108727]
train loss: 1.953375  [25600/108727]
train loss: 1.536290  [28800/108727]
train loss: 2.740369  [32000/108727]
train loss: 1.812345  [35200/108727]
train loss: 2.853370  [38400/108727]
train loss: 1.390280  [41600/108727]
train loss: 2.744755  [44800/108727]
train loss: 1.837380  [48000/108727]
train loss: 2.206244  [51200/108727]
train loss: 1.749335  [54400/108727]
train loss: 1.523443  [57600/108727]
train loss: 2.268728  [60800/108727]
train loss: 3.385020  [64000/108727]
train loss: 2.211134  [67200/108727]
train loss: 1.446303  [70400/108727]
train loss: 1.586104  [73600/108727]
train loss: 2.501467  [76800/108727]
train loss: 2.042575  [80000/108727]
train loss: 2.110252  [83200/108727]
train loss: 1.448465  [86400/108727]
train loss: 3.185207  [89600/108727]
train loss: 1.398160  [92800/108727]
train loss: 1.825266  [96000/108727]
train loss: 2.971263  [99200/108727]
train loss: 1.373992  [102400/108727]
train loss: 2.155988  [105600/108727]
Avg validation loss: 2.192083
Avg out-of-distribution loss: 2.479731
Epoch 9
-------------------------------
train loss: 1.997161  [    0/108727]
train loss: 1.838213  [ 3200/108727]
train loss: 2.069612  [ 6400/108727]
train loss: 3.034033  [ 9600/108727]
train loss: 1.851971  [12800/108727]
train loss: 2.231447  [16000/108727]
train loss: 1.384023  [19200/108727]
train loss: 1.297625  [22400/108727]
train loss: 0.783828  [25600/108727]
train loss: 2.879395  [28800/108727]
train loss: 1.173019  [32000/108727]
train loss: 1.642213  [35200/108727]
train loss: 1.717590  [38400/108727]
train loss: 1.747051  [41600/108727]
train loss: 1.612589  [44800/108727]
train loss: 2.098732  [48000/108727]
train loss: 2.118947  [51200/108727]
train loss: 1.861293  [54400/108727]
train loss: 1.657704  [57600/108727]
train loss: 1.738677  [60800/108727]
train loss: 2.008592  [64000/108727]
train loss: 1.012045  [67200/108727]
train loss: 1.136457  [70400/108727]
train loss: 3.005630  [73600/108727]
train loss: 1.336446  [76800/108727]
train loss: 2.266261  [80000/108727]
train loss: 1.248765  [83200/108727]
train loss: 1.262290  [86400/108727]
train loss: 1.632246  [89600/108727]
train loss: 1.938749  [92800/108727]
train loss: 3.292390  [96000/108727]
train loss: 1.211288  [99200/108727]
train loss: 1.952150  [102400/108727]
train loss: 3.591539  [105600/108727]
Avg validation loss: 2.063736
Avg out-of-distribution loss: 2.293286
Epoch 10
-------------------------------
train loss: 1.510726  [    0/108727]
train loss: 1.588475  [ 3200/108727]
train loss: 1.837361  [ 6400/108727]
train loss: 4.041198  [ 9600/108727]
train loss: 1.641083  [12800/108727]
train loss: 1.990019  [16000/108727]
train loss: 1.902544  [19200/108727]
train loss: 1.419763  [22400/108727]
train loss: 1.275239  [25600/108727]
train loss: 1.318589  [28800/108727]
train loss: 1.448594  [32000/108727]
train loss: 1.470508  [35200/108727]
train loss: 1.276576  [38400/108727]
train loss: 1.351016  [41600/108727]
train loss: 1.731275  [44800/108727]
train loss: 1.545546  [48000/108727]
train loss: 1.869459  [51200/108727]
train loss: 1.378808  [54400/108727]
train loss: 1.832151  [57600/108727]
train loss: 2.525283  [60800/108727]
train loss: 2.325917  [64000/108727]
train loss: 1.208059  [67200/108727]
train loss: 1.689829  [70400/108727]
train loss: 0.947912  [73600/108727]
train loss: 1.177718  [76800/108727]
train loss: 2.913968  [80000/108727]
train loss: 1.426668  [83200/108727]
train loss: 1.145384  [86400/108727]
train loss: 1.910329  [89600/108727]
train loss: 1.444011  [92800/108727]
train loss: 2.136461  [96000/108727]
train loss: 1.632189  [99200/108727]
train loss: 1.610325  [102400/108727]
train loss: 1.623083  [105600/108727]
Avg validation loss: 1.672170
Avg out-of-distribution loss: 2.016843
Epoch 11
-------------------------------
train loss: 1.196447  [    0/108727]
train loss: 1.903175  [ 3200/108727]
train loss: 1.052362  [ 6400/108727]
train loss: 1.396505  [ 9600/108727]
train loss: 1.372902  [12800/108727]
train loss: 1.102323  [16000/108727]
train loss: 1.456693  [19200/108727]
train loss: 1.164925  [22400/108727]
train loss: 1.448976  [25600/108727]
train loss: 1.335719  [28800/108727]
train loss: 0.991058  [32000/108727]
train loss: 1.151675  [35200/108727]
train loss: 1.568963  [38400/108727]
train loss: 1.047969  [41600/108727]
train loss: 1.501511  [44800/108727]
train loss: 1.229374  [48000/108727]
train loss: 1.246267  [51200/108727]
train loss: 2.130793  [54400/108727]
train loss: 1.907043  [57600/108727]
train loss: 1.556746  [60800/108727]
train loss: 1.381148  [64000/108727]
train loss: 1.153298  [67200/108727]
train loss: 1.512939  [70400/108727]
train loss: 1.991373  [73600/108727]
train loss: 1.623433  [76800/108727]
train loss: 1.615018  [80000/108727]
train loss: 2.025563  [83200/108727]
train loss: 1.158467  [86400/108727]
train loss: 1.395945  [89600/108727]
train loss: 2.799438  [92800/108727]
train loss: 1.300375  [96000/108727]
train loss: 2.889395  [99200/108727]
train loss: 1.519090  [102400/108727]
train loss: 1.522977  [105600/108727]
Avg validation loss: 2.094495
Avg out-of-distribution loss: 2.400189
Epoch 12
-------------------------------
train loss: 1.449620  [    0/108727]
train loss: 1.224837  [ 3200/108727]
train loss: 1.146614  [ 6400/108727]
train loss: 1.597039  [ 9600/108727]
train loss: 1.257698  [12800/108727]
train loss: 1.169116  [16000/108727]
train loss: 2.512288  [19200/108727]
train loss: 1.348460  [22400/108727]
train loss: 1.165294  [25600/108727]
train loss: 1.861306  [28800/108727]
train loss: 1.680403  [32000/108727]
train loss: 1.815268  [35200/108727]
train loss: 1.531587  [38400/108727]
train loss: 1.516715  [41600/108727]
train loss: 1.297050  [44800/108727]
train loss: 3.410992  [48000/108727]
train loss: 1.419768  [51200/108727]
train loss: 1.769485  [54400/108727]
train loss: 2.685598  [57600/108727]
train loss: 1.528153  [60800/108727]
train loss: 0.821643  [64000/108727]
train loss: 0.821886  [67200/108727]
train loss: 0.836742  [70400/108727]
train loss: 1.673998  [73600/108727]
train loss: 1.481580  [76800/108727]
train loss: 2.008483  [80000/108727]
train loss: 1.449971  [83200/108727]
train loss: 1.296864  [86400/108727]
train loss: 2.433830  [89600/108727]
train loss: 1.044209  [92800/108727]
train loss: 1.954460  [96000/108727]
train loss: 0.955089  [99200/108727]
train loss: 1.484231  [102400/108727]
train loss: 1.436121  [105600/108727]
Avg validation loss: 1.565153
Avg out-of-distribution loss: 1.810601
Epoch 13
-------------------------------
train loss: 1.177790  [    0/108727]
train loss: 1.571731  [ 3200/108727]
train loss: 1.350278  [ 6400/108727]
train loss: 2.343151  [ 9600/108727]
train loss: 1.493927  [12800/108727]
train loss: 1.655490  [16000/108727]
train loss: 1.060170  [19200/108727]
train loss: 0.932671  [22400/108727]
train loss: 1.603640  [25600/108727]
train loss: 1.140716  [28800/108727]
train loss: 1.810255  [32000/108727]
train loss: 1.012161  [35200/108727]
train loss: 1.690672  [38400/108727]
train loss: 1.261545  [41600/108727]
train loss: 1.403227  [44800/108727]
train loss: 1.432877  [48000/108727]
train loss: 1.274915  [51200/108727]
train loss: 1.308194  [54400/108727]
train loss: 1.461091  [57600/108727]
train loss: 1.874848  [60800/108727]
train loss: 1.470269  [64000/108727]
train loss: 1.010641  [67200/108727]
train loss: 1.532401  [70400/108727]
train loss: 0.881399  [73600/108727]
train loss: 1.935722  [76800/108727]
train loss: 2.209687  [80000/108727]
train loss: 1.577546  [83200/108727]
train loss: 1.485557  [86400/108727]
train loss: 2.272473  [89600/108727]
train loss: 1.491101  [92800/108727]
train loss: 2.124539  [96000/108727]
train loss: 1.777371  [99200/108727]
train loss: 0.942988  [102400/108727]
train loss: 1.505719  [105600/108727]
Avg validation loss: 1.369847
Avg out-of-distribution loss: 1.591385
Epoch 14
-------------------------------
train loss: 1.398336  [    0/108727]
train loss: 1.912257  [ 3200/108727]
train loss: 1.163015  [ 6400/108727]
train loss: 1.746219  [ 9600/108727]
train loss: 1.032224  [12800/108727]
train loss: 1.756585  [16000/108727]
train loss: 1.102025  [19200/108727]
train loss: 1.185357  [22400/108727]
train loss: 0.902333  [25600/108727]
train loss: 1.147332  [28800/108727]
train loss: 1.481298  [32000/108727]
train loss: 1.285865  [35200/108727]
train loss: 1.597217  [38400/108727]
train loss: 1.462507  [41600/108727]
train loss: 1.223434  [44800/108727]
train loss: 2.038480  [48000/108727]
train loss: 0.776277  [51200/108727]
train loss: 1.449298  [54400/108727]
train loss: 1.120064  [57600/108727]
train loss: 3.454802  [60800/108727]
train loss: 2.086391  [64000/108727]
train loss: 1.267951  [67200/108727]
train loss: 1.170476  [70400/108727]
train loss: 0.805307  [73600/108727]
train loss: 1.370381  [76800/108727]
train loss: 0.866609  [80000/108727]
train loss: 1.507651  [83200/108727]
train loss: 1.118180  [86400/108727]
train loss: 1.383204  [89600/108727]
train loss: 1.120796  [92800/108727]
train loss: 0.942238  [96000/108727]
train loss: 1.663359  [99200/108727]
train loss: 2.192142  [102400/108727]
train loss: 2.110620  [105600/108727]
Avg validation loss: 1.431209
Avg out-of-distribution loss: 1.699385
Epoch 15
-------------------------------
train loss: 1.291332  [    0/108727]
train loss: 1.187319  [ 3200/108727]
train loss: 0.842695  [ 6400/108727]
train loss: 0.922734  [ 9600/108727]
train loss: 1.487334  [12800/108727]
train loss: 0.901780  [16000/108727]
train loss: 1.737641  [19200/108727]
train loss: 1.201453  [22400/108727]
train loss: 0.975769  [25600/108727]
train loss: 1.160982  [28800/108727]
train loss: 2.549560  [32000/108727]
train loss: 1.139625  [35200/108727]
train loss: 0.969458  [38400/108727]
train loss: 2.073119  [41600/108727]
train loss: 1.975919  [44800/108727]
train loss: 1.391056  [48000/108727]
train loss: 1.409542  [51200/108727]
train loss: 1.193618  [54400/108727]
train loss: 1.445816  [57600/108727]
train loss: 0.943501  [60800/108727]
train loss: 1.229729  [64000/108727]
train loss: 1.101308  [67200/108727]
train loss: 1.325414  [70400/108727]
train loss: 1.536345  [73600/108727]
train loss: 1.218169  [76800/108727]
train loss: 1.397049  [80000/108727]
train loss: 1.329571  [83200/108727]
train loss: 1.247094  [86400/108727]
train loss: 1.191308  [89600/108727]
train loss: 1.178728  [92800/108727]
train loss: 1.129654  [96000/108727]
train loss: 2.101923  [99200/108727]
train loss: 0.826207  [102400/108727]
train loss: 1.921076  [105600/108727]
Avg validation loss: 1.091449
Avg out-of-distribution loss: 1.408308
Epoch 16
-------------------------------
train loss: 1.024769  [    0/108727]
train loss: 1.221806  [ 3200/108727]
train loss: 1.343784  [ 6400/108727]
train loss: 1.774341  [ 9600/108727]
train loss: 1.072344  [12800/108727]
train loss: 1.162214  [16000/108727]
train loss: 1.275821  [19200/108727]
train loss: 1.033372  [22400/108727]
train loss: 1.832344  [25600/108727]
train loss: 1.334830  [28800/108727]
train loss: 1.363762  [32000/108727]
train loss: 1.247341  [35200/108727]
train loss: 1.533148  [38400/108727]
train loss: 1.709565  [41600/108727]
train loss: 1.250833  [44800/108727]
train loss: 1.377771  [48000/108727]
train loss: 0.759385  [51200/108727]
train loss: 1.255149  [54400/108727]
train loss: 1.410257  [57600/108727]
train loss: 1.645688  [60800/108727]
train loss: 1.405685  [64000/108727]
train loss: 1.231757  [67200/108727]
train loss: 1.000133  [70400/108727]
train loss: 1.213535  [73600/108727]
train loss: 1.656931  [76800/108727]
train loss: 0.917142  [80000/108727]
train loss: 1.811227  [83200/108727]
train loss: 1.225243  [86400/108727]
train loss: 1.291005  [89600/108727]
train loss: 1.146636  [92800/108727]
train loss: 1.111458  [96000/108727]
train loss: 1.453667  [99200/108727]
train loss: 1.402035  [102400/108727]
train loss: 0.825816  [105600/108727]
Avg validation loss: 1.310598
Avg out-of-distribution loss: 1.565435
Epoch 17
-------------------------------
train loss: 1.375757  [    0/108727]
train loss: 1.968428  [ 3200/108727]
train loss: 0.693234  [ 6400/108727]
train loss: 0.707902  [ 9600/108727]
train loss: 1.290954  [12800/108727]
train loss: 1.529536  [16000/108727]
train loss: 0.707211  [19200/108727]
train loss: 1.214657  [22400/108727]
train loss: 0.826912  [25600/108727]
train loss: 1.147130  [28800/108727]
train loss: 1.191121  [32000/108727]
train loss: 1.266187  [35200/108727]
train loss: 1.872102  [38400/108727]
train loss: 1.157209  [41600/108727]
train loss: 1.689005  [44800/108727]
train loss: 1.084602  [48000/108727]
train loss: 1.164464  [51200/108727]
train loss: 1.181597  [54400/108727]
train loss: 0.979977  [57600/108727]
train loss: 1.588006  [60800/108727]
train loss: 1.184680  [64000/108727]
train loss: 2.100111  [67200/108727]
train loss: 1.523035  [70400/108727]
train loss: 1.711743  [73600/108727]
train loss: 1.540594  [76800/108727]
train loss: 1.151088  [80000/108727]
train loss: 1.120039  [83200/108727]
train loss: 0.603140  [86400/108727]
train loss: 0.998665  [89600/108727]
train loss: 0.666350  [92800/108727]
train loss: 0.761164  [96000/108727]
train loss: 1.118367  [99200/108727]
train loss: 1.131617  [102400/108727]
train loss: 0.975999  [105600/108727]
Avg validation loss: 1.249242
Avg out-of-distribution loss: 1.583880
Epoch 18
-------------------------------
train loss: 1.444614  [    0/108727]
train loss: 0.715763  [ 3200/108727]
train loss: 1.515435  [ 6400/108727]
train loss: 1.239573  [ 9600/108727]
train loss: 0.871623  [12800/108727]
train loss: 1.369776  [16000/108727]
train loss: 1.676500  [19200/108727]
train loss: 2.398186  [22400/108727]
train loss: 1.272328  [25600/108727]
train loss: 0.948016  [28800/108727]
train loss: 1.895389  [32000/108727]
train loss: 0.974088  [35200/108727]
train loss: 1.986153  [38400/108727]
train loss: 1.760404  [41600/108727]
train loss: 1.139691  [44800/108727]
train loss: 0.980800  [48000/108727]
train loss: 0.952819  [51200/108727]
train loss: 2.199657  [54400/108727]
train loss: 1.104374  [57600/108727]
train loss: 1.350578  [60800/108727]
train loss: 1.042411  [64000/108727]
train loss: 1.771252  [67200/108727]
train loss: 0.838408  [70400/108727]
train loss: 1.245305  [73600/108727]
train loss: 1.652840  [76800/108727]
train loss: 1.252193  [80000/108727]
train loss: 1.748443  [83200/108727]
train loss: 1.427441  [86400/108727]
train loss: 0.806077  [89600/108727]
train loss: 1.612473  [92800/108727]
train loss: 0.834095  [96000/108727]
train loss: 1.112131  [99200/108727]
train loss: 1.245836  [102400/108727]
train loss: 1.562874  [105600/108727]
Avg validation loss: 1.199818
Avg out-of-distribution loss: 1.467007
Epoch 19
-------------------------------
train loss: 1.277720  [    0/108727]
train loss: 2.337572  [ 3200/108727]
train loss: 1.523932  [ 6400/108727]
train loss: 1.278073  [ 9600/108727]
train loss: 2.164999  [12800/108727]
train loss: 0.991282  [16000/108727]
train loss: 1.070840  [19200/108727]
train loss: 0.909601  [22400/108727]
train loss: 1.408515  [25600/108727]
train loss: 0.885439  [28800/108727]
train loss: 1.963846  [32000/108727]
train loss: 1.194496  [35200/108727]
train loss: 0.925376  [38400/108727]
train loss: 1.037761  [41600/108727]
train loss: 1.623486  [44800/108727]
train loss: 1.484027  [48000/108727]
train loss: 1.471791  [51200/108727]
train loss: 0.960383  [54400/108727]
train loss: 1.368242  [57600/108727]
train loss: 1.231611  [60800/108727]
train loss: 0.873515  [64000/108727]
train loss: 1.326892  [67200/108727]
train loss: 1.172003  [70400/108727]
train loss: 1.258225  [73600/108727]
train loss: 0.853150  [76800/108727]
train loss: 1.258141  [80000/108727]
train loss: 1.374622  [83200/108727]
train loss: 3.932824  [86400/108727]
train loss: 0.752684  [89600/108727]
train loss: 1.498753  [92800/108727]
train loss: 0.984472  [96000/108727]
train loss: 1.252342  [99200/108727]
train loss: 0.916377  [102400/108727]
train loss: 0.756034  [105600/108727]
Avg validation loss: 1.173349
Avg out-of-distribution loss: 1.437354
Epoch 20
-------------------------------
train loss: 0.743427  [    0/108727]
train loss: 1.150373  [ 3200/108727]
train loss: 1.560855  [ 6400/108727]
train loss: 1.040709  [ 9600/108727]
train loss: 0.969780  [12800/108727]
train loss: 1.287192  [16000/108727]
train loss: 2.194320  [19200/108727]
train loss: 1.203897  [22400/108727]
train loss: 1.372776  [25600/108727]
train loss: 1.069885  [28800/108727]
train loss: 0.837004  [32000/108727]
train loss: 0.580646  [35200/108727]
train loss: 1.644700  [38400/108727]
train loss: 1.275846  [41600/108727]
train loss: 0.930955  [44800/108727]
train loss: 1.177657  [48000/108727]
train loss: 1.302844  [51200/108727]
train loss: 0.914457  [54400/108727]
train loss: 1.356043  [57600/108727]
train loss: 1.193712  [60800/108727]
train loss: 2.179076  [64000/108727]
train loss: 0.615725  [67200/108727]
train loss: 0.850621  [70400/108727]
train loss: 1.291757  [73600/108727]
train loss: 1.104974  [76800/108727]
train loss: 1.654065  [80000/108727]
train loss: 0.873041  [83200/108727]
train loss: 1.141941  [86400/108727]
train loss: 1.343437  [89600/108727]
train loss: 1.008437  [92800/108727]
train loss: 0.913983  [96000/108727]
train loss: 0.869089  [99200/108727]
train loss: 0.975169  [102400/108727]
train loss: 1.768347  [105600/108727]
Avg validation loss: 1.046400
Avg out-of-distribution loss: 1.296584
Epoch 21
-------------------------------
train loss: 1.189545  [    0/108727]
train loss: 1.047166  [ 3200/108727]
train loss: 1.279722  [ 6400/108727]
train loss: 0.861776  [ 9600/108727]
train loss: 0.824674  [12800/108727]
train loss: 1.577039  [16000/108727]
train loss: 0.858876  [19200/108727]
train loss: 0.709691  [22400/108727]
train loss: 1.287742  [25600/108727]
train loss: 0.780303  [28800/108727]
train loss: 2.547827  [32000/108727]
train loss: 1.318845  [35200/108727]
train loss: 0.819184  [38400/108727]
train loss: 0.739222  [41600/108727]
train loss: 1.364474  [44800/108727]
train loss: 0.832497  [48000/108727]
train loss: 1.653084  [51200/108727]
train loss: 1.990456  [54400/108727]
train loss: 0.833568  [57600/108727]
train loss: 0.887440  [60800/108727]
train loss: 1.656148  [64000/108727]
train loss: 0.836624  [67200/108727]
train loss: 0.663356  [70400/108727]
train loss: 1.204660  [73600/108727]
train loss: 0.753999  [76800/108727]
train loss: 0.982807  [80000/108727]
train loss: 0.903459  [83200/108727]
train loss: 0.964256  [86400/108727]
train loss: 1.130311  [89600/108727]
train loss: 1.238051  [92800/108727]
train loss: 1.184690  [96000/108727]
train loss: 1.293322  [99200/108727]
train loss: 1.289206  [102400/108727]
train loss: 0.993397  [105600/108727]
Avg validation loss: 1.314969
Avg out-of-distribution loss: 1.512515
Epoch 22
-------------------------------
train loss: 1.122726  [    0/108727]
train loss: 0.956977  [ 3200/108727]
train loss: 0.854701  [ 6400/108727]
train loss: 0.923652  [ 9600/108727]
train loss: 1.167232  [12800/108727]
train loss: 0.957638  [16000/108727]
train loss: 1.681191  [19200/108727]
train loss: 1.222864  [22400/108727]
train loss: 0.921918  [25600/108727]
train loss: 1.728592  [28800/108727]
train loss: 1.139277  [32000/108727]
train loss: 1.058098  [35200/108727]
train loss: 1.920076  [38400/108727]
train loss: 0.995268  [41600/108727]
train loss: 0.896494  [44800/108727]
train loss: 0.799503  [48000/108727]
train loss: 1.133351  [51200/108727]
train loss: 0.794427  [54400/108727]
train loss: 1.249266  [57600/108727]
train loss: 1.086959  [60800/108727]
train loss: 1.720314  [64000/108727]
train loss: 0.659710  [67200/108727]
train loss: 0.996036  [70400/108727]
train loss: 1.394416  [73600/108727]
train loss: 0.903801  [76800/108727]
train loss: 0.746440  [80000/108727]
train loss: 0.786461  [83200/108727]
train loss: 0.763160  [86400/108727]
train loss: 0.761184  [89600/108727]
train loss: 1.929495  [92800/108727]
train loss: 1.016252  [96000/108727]
train loss: 1.170188  [99200/108727]
train loss: 1.015855  [102400/108727]
train loss: 2.195548  [105600/108727]
Avg validation loss: 1.287383
Avg out-of-distribution loss: 1.497797
Epoch 23
-------------------------------
train loss: 1.247330  [    0/108727]
train loss: 1.433265  [ 3200/108727]
train loss: 0.694222  [ 6400/108727]
train loss: 0.887107  [ 9600/108727]
train loss: 2.219077  [12800/108727]
train loss: 0.820231  [16000/108727]
train loss: 0.759788  [19200/108727]
train loss: 0.754668  [22400/108727]
train loss: 1.238326  [25600/108727]
train loss: 0.846643  [28800/108727]
train loss: 0.826879  [32000/108727]
train loss: 0.945978  [35200/108727]
train loss: 0.916831  [38400/108727]
train loss: 1.129157  [41600/108727]
train loss: 1.124402  [44800/108727]
train loss: 0.646322  [48000/108727]
train loss: 1.211811  [51200/108727]
train loss: 1.417470  [54400/108727]
train loss: 0.993049  [57600/108727]
train loss: 1.068436  [60800/108727]
train loss: 0.668625  [64000/108727]
train loss: 0.750565  [67200/108727]
train loss: 1.401047  [70400/108727]
train loss: 1.020896  [73600/108727]
train loss: 0.800242  [76800/108727]
train loss: 1.074013  [80000/108727]
train loss: 1.276605  [83200/108727]
train loss: 0.890315  [86400/108727]
train loss: 1.273318  [89600/108727]
train loss: 1.802995  [92800/108727]
train loss: 2.689572  [96000/108727]
train loss: 1.027065  [99200/108727]
train loss: 0.906248  [102400/108727]
train loss: 0.941944  [105600/108727]
Avg validation loss: 0.961959
Avg out-of-distribution loss: 1.298207
Epoch 24
-------------------------------
train loss: 0.562939  [    0/108727]
train loss: 1.919918  [ 3200/108727]
train loss: 0.867045  [ 6400/108727]
train loss: 1.301703  [ 9600/108727]
train loss: 0.855840  [12800/108727]
train loss: 1.054617  [16000/108727]
train loss: 1.180849  [19200/108727]
train loss: 1.867625  [22400/108727]
train loss: 1.349918  [25600/108727]
train loss: 0.983833  [28800/108727]
train loss: 0.739978  [32000/108727]
train loss: 0.725054  [35200/108727]
train loss: 1.012380  [38400/108727]
train loss: 0.716626  [41600/108727]
train loss: 1.104304  [44800/108727]
train loss: 1.120863  [48000/108727]
train loss: 1.241652  [51200/108727]
train loss: 1.348315  [54400/108727]
train loss: 1.439175  [57600/108727]
train loss: 1.062031  [60800/108727]
train loss: 1.077715  [64000/108727]
train loss: 0.701934  [67200/108727]
train loss: 1.467707  [70400/108727]
train loss: 1.033591  [73600/108727]
train loss: 1.230389  [76800/108727]
train loss: 1.077190  [80000/108727]
train loss: 1.242170  [83200/108727]
train loss: 1.254923  [86400/108727]
train loss: 0.746854  [89600/108727]
train loss: 0.950497  [92800/108727]
train loss: 1.641011  [96000/108727]
train loss: 0.679490  [99200/108727]
train loss: 1.336395  [102400/108727]
train loss: 0.795363  [105600/108727]
Avg validation loss: 1.098000
Avg out-of-distribution loss: 1.369214
Epoch 25
-------------------------------
train loss: 1.237316  [    0/108727]
train loss: 1.573607  [ 3200/108727]
train loss: 1.028839  [ 6400/108727]
train loss: 1.214785  [ 9600/108727]
train loss: 1.336198  [12800/108727]
train loss: 0.887197  [16000/108727]
train loss: 1.000520  [19200/108727]
train loss: 1.045135  [22400/108727]
train loss: 0.826814  [25600/108727]
train loss: 0.603776  [28800/108727]
train loss: 1.618289  [32000/108727]
train loss: 1.166630  [35200/108727]
train loss: 0.628421  [38400/108727]
train loss: 0.933890  [41600/108727]
train loss: 0.986683  [44800/108727]
train loss: 0.678836  [48000/108727]
train loss: 0.931480  [51200/108727]
train loss: 0.926253  [54400/108727]
train loss: 1.005924  [57600/108727]
train loss: 0.711988  [60800/108727]
train loss: 0.784287  [64000/108727]
train loss: 0.994051  [67200/108727]
train loss: 1.210722  [70400/108727]
train loss: 0.929949  [73600/108727]
train loss: 1.244202  [76800/108727]
train loss: 1.204660  [80000/108727]
train loss: 5.918302  [83200/108727]
train loss: 1.314958  [86400/108727]
train loss: 0.712812  [89600/108727]
train loss: 0.676968  [92800/108727]
train loss: 0.639974  [96000/108727]
train loss: 0.749678  [99200/108727]
train loss: 0.637012  [102400/108727]
train loss: 0.946362  [105600/108727]
Avg validation loss: 1.034709
Avg out-of-distribution loss: 1.324614
Epoch 26
-------------------------------
train loss: 0.793730  [    0/108727]
train loss: 1.090318  [ 3200/108727]
train loss: 0.688046  [ 6400/108727]
train loss: 1.071606  [ 9600/108727]
train loss: 0.739897  [12800/108727]
train loss: 1.122658  [16000/108727]
train loss: 1.706193  [19200/108727]
train loss: 0.773479  [22400/108727]
train loss: 1.792504  [25600/108727]
train loss: 0.983894  [28800/108727]
train loss: 0.901929  [32000/108727]
train loss: 1.239547  [35200/108727]
train loss: 0.755107  [38400/108727]
train loss: 0.985332  [41600/108727]
train loss: 1.155439  [44800/108727]
train loss: 0.647863  [48000/108727]
train loss: 0.777405  [51200/108727]
train loss: 1.211811  [54400/108727]
train loss: 0.638920  [57600/108727]
train loss: 1.240953  [60800/108727]
train loss: 0.901769  [64000/108727]
train loss: 2.572823  [67200/108727]
train loss: 0.786596  [70400/108727]
train loss: 0.930510  [73600/108727]
train loss: 1.408152  [76800/108727]
train loss: 0.707775  [80000/108727]
train loss: 1.020490  [83200/108727]
train loss: 0.946555  [86400/108727]
train loss: 1.233800  [89600/108727]
train loss: 0.828089  [92800/108727]
train loss: 1.434059  [96000/108727]
train loss: 0.983972  [99200/108727]
train loss: 1.162857  [102400/108727]
train loss: 1.517745  [105600/108727]
Avg validation loss: 0.950962
Avg out-of-distribution loss: 1.266722
Epoch 27
-------------------------------
train loss: 0.981875  [    0/108727]
train loss: 2.204309  [ 3200/108727]
train loss: 1.943898  [ 6400/108727]
train loss: 0.719166  [ 9600/108727]
train loss: 1.031713  [12800/108727]
train loss: 5.350976  [16000/108727]
train loss: 0.593939  [19200/108727]
train loss: 0.966017  [22400/108727]
train loss: 1.175864  [25600/108727]
train loss: 0.920357  [28800/108727]
train loss: 0.735229  [32000/108727]
train loss: 0.770446  [35200/108727]
train loss: 0.898380  [38400/108727]
train loss: 1.347697  [41600/108727]
train loss: 1.417909  [44800/108727]
train loss: 1.014979  [48000/108727]
train loss: 1.316899  [51200/108727]
train loss: 0.468172  [54400/108727]
train loss: 1.317122  [57600/108727]
train loss: 0.638219  [60800/108727]
train loss: 0.989875  [64000/108727]
train loss: 0.751387  [67200/108727]
train loss: 1.770819  [70400/108727]
train loss: 1.418138  [73600/108727]
train loss: 1.210011  [76800/108727]
train loss: 0.626530  [80000/108727]
train loss: 1.927621  [83200/108727]
train loss: 1.139211  [86400/108727]
train loss: 0.778511  [89600/108727]
train loss: 0.855787  [92800/108727]
train loss: 0.953203  [96000/108727]
train loss: 1.124264  [99200/108727]
train loss: 0.844237  [102400/108727]
train loss: 0.994700  [105600/108727]
Avg validation loss: 1.161581
Avg out-of-distribution loss: 1.476297
Epoch 28
-------------------------------
train loss: 0.953390  [    0/108727]
train loss: 0.740316  [ 3200/108727]
train loss: 1.077294  [ 6400/108727]
train loss: 1.103747  [ 9600/108727]
train loss: 0.739068  [12800/108727]
train loss: 0.929131  [16000/108727]
train loss: 1.733109  [19200/108727]
train loss: 1.353593  [22400/108727]
train loss: 1.805031  [25600/108727]
train loss: 0.856171  [28800/108727]
train loss: 1.323891  [32000/108727]
train loss: 0.830105  [35200/108727]
train loss: 0.967632  [38400/108727]
train loss: 1.218468  [41600/108727]
train loss: 0.727400  [44800/108727]
train loss: 0.456603  [48000/108727]
train loss: 0.795411  [51200/108727]
train loss: 0.908241  [54400/108727]
train loss: 1.715787  [57600/108727]
train loss: 1.876790  [60800/108727]
train loss: 0.968208  [64000/108727]
train loss: 0.568175  [67200/108727]
train loss: 0.702937  [70400/108727]
train loss: 0.746841  [73600/108727]
train loss: 1.066972  [76800/108727]
train loss: 1.707948  [80000/108727]
train loss: 1.107593  [83200/108727]
train loss: 0.802432  [86400/108727]
train loss: 1.095406  [89600/108727]
train loss: 1.248421  [92800/108727]
train loss: 0.820346  [96000/108727]
train loss: 1.158697  [99200/108727]
train loss: 1.124009  [102400/108727]
train loss: 1.450839  [105600/108727]
Avg validation loss: 0.947679
Avg out-of-distribution loss: 1.248417
Epoch 29
-------------------------------
train loss: 1.090168  [    0/108727]
train loss: 1.689567  [ 3200/108727]
train loss: 0.740691  [ 6400/108727]
train loss: 1.935392  [ 9600/108727]
train loss: 0.913111  [12800/108727]
train loss: 0.839668  [16000/108727]
train loss: 0.714849  [19200/108727]
train loss: 0.788339  [22400/108727]
train loss: 1.540805  [25600/108727]
train loss: 0.846406  [28800/108727]
train loss: 0.509647  [32000/108727]
train loss: 1.099801  [35200/108727]
train loss: 0.988626  [38400/108727]
train loss: 1.392827  [41600/108727]
train loss: 0.727991  [44800/108727]
train loss: 1.124545  [48000/108727]
train loss: 1.438178  [51200/108727]
train loss: 1.228786  [54400/108727]
train loss: 0.827354  [57600/108727]
train loss: 1.535812  [60800/108727]
train loss: 1.603357  [64000/108727]
train loss: 1.436026  [67200/108727]
train loss: 1.344219  [70400/108727]
train loss: 0.775601  [73600/108727]
train loss: 1.571315  [76800/108727]
train loss: 1.209972  [80000/108727]
train loss: 0.643516  [83200/108727]
train loss: 1.426615  [86400/108727]
train loss: 0.756538  [89600/108727]
train loss: 0.879749  [92800/108727]
train loss: 0.997989  [96000/108727]
train loss: 0.776020  [99200/108727]
train loss: 0.623440  [102400/108727]
train loss: 0.969353  [105600/108727]
Avg validation loss: 0.993563
Avg out-of-distribution loss: 1.369428
Epoch 30
-------------------------------
train loss: 0.898724  [    0/108727]
train loss: 0.766246  [ 3200/108727]
train loss: 0.854626  [ 6400/108727]
train loss: 2.020699  [ 9600/108727]
train loss: 1.174834  [12800/108727]
train loss: 1.257721  [16000/108727]
train loss: 1.594859  [19200/108727]
train loss: 1.076188  [22400/108727]
train loss: 1.043407  [25600/108727]
train loss: 1.079787  [28800/108727]
train loss: 1.390810  [32000/108727]
train loss: 1.313213  [35200/108727]
train loss: 0.856644  [38400/108727]
train loss: 1.153823  [41600/108727]
train loss: 1.211191  [44800/108727]
train loss: 1.115544  [48000/108727]
train loss: 1.206708  [51200/108727]
train loss: 0.792676  [54400/108727]
train loss: 0.810129  [57600/108727]
train loss: 0.828791  [60800/108727]
train loss: 1.174110  [64000/108727]
train loss: 1.421047  [67200/108727]
train loss: 1.102674  [70400/108727]
train loss: 1.202891  [73600/108727]
train loss: 1.031928  [76800/108727]
train loss: 0.884285  [80000/108727]
train loss: 0.697069  [83200/108727]
train loss: 0.628550  [86400/108727]
train loss: 0.634483  [89600/108727]
train loss: 1.411904  [92800/108727]
train loss: 0.556865  [96000/108727]
train loss: 0.928564  [99200/108727]
train loss: 0.837042  [102400/108727]
train loss: 0.688429  [105600/108727]
Avg validation loss: 1.114461
Avg out-of-distribution loss: 1.362974
Done!