Shape of X: torch.Size([32, 31])
Shape of y: torch.Size([32, 5]) torch.float32
Using cpu device
NeuralNetwork(
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=31, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=5, bias=True)
  )
)
Epoch 1
-------------------------------
train loss: 7570.541504  [    0/108727]
train loss: 119.092079  [ 3200/108727]
train loss: 13.961680  [ 6400/108727]
train loss: 5.654185  [ 9600/108727]
train loss: 5.925403  [12800/108727]
train loss: 6.755800  [16000/108727]
train loss: 8.294497  [19200/108727]
train loss: 7.782819  [22400/108727]
train loss: 4.553774  [25600/108727]
train loss: 7.870417  [28800/108727]
train loss: 6.460401  [32000/108727]
train loss: 9.681599  [35200/108727]
train loss: 6.194912  [38400/108727]
train loss: 8.555203  [41600/108727]
train loss: 4.021949  [44800/108727]
train loss: 4.968002  [48000/108727]
train loss: 5.463337  [51200/108727]
train loss: 4.845843  [54400/108727]
train loss: 7.736347  [57600/108727]
train loss: 8.883539  [60800/108727]
train loss: 4.314458  [64000/108727]
train loss: 7.689990  [67200/108727]
train loss: 3.964617  [70400/108727]
train loss: 7.187528  [73600/108727]
train loss: 4.698426  [76800/108727]
train loss: 11.396883  [80000/108727]
train loss: 3.235137  [83200/108727]
train loss: 11.833898  [86400/108727]
train loss: 3.583028  [89600/108727]
train loss: 11.236601  [92800/108727]
train loss: 3.866709  [96000/108727]
train loss: 2.582098  [99200/108727]
train loss: 4.188503  [102400/108727]
train loss: 6.356375  [105600/108727]
Avg validation loss: 6.613199
Epoch 2
-------------------------------
train loss: 6.402407  [    0/108727]
train loss: 5.091405  [ 3200/108727]
train loss: 11.803286  [ 6400/108727]
train loss: 2.610780  [ 9600/108727]
train loss: 5.621573  [12800/108727]
train loss: 2.217735  [16000/108727]
train loss: 3.310106  [19200/108727]
train loss: 4.127386  [22400/108727]
train loss: 2.724070  [25600/108727]
train loss: 3.711201  [28800/108727]
train loss: 6.674983  [32000/108727]
train loss: 2.915147  [35200/108727]
train loss: 4.612920  [38400/108727]
train loss: 4.079479  [41600/108727]
train loss: 6.013009  [44800/108727]
train loss: 8.668961  [48000/108727]
train loss: 5.105643  [51200/108727]
train loss: 5.883206  [54400/108727]
train loss: 3.344800  [57600/108727]
train loss: 2.788066  [60800/108727]
train loss: 5.622403  [64000/108727]
train loss: 4.617780  [67200/108727]
train loss: 5.953040  [70400/108727]
train loss: 4.698071  [73600/108727]
train loss: 4.394621  [76800/108727]
train loss: 3.540801  [80000/108727]
train loss: 10.389174  [83200/108727]
train loss: 4.638100  [86400/108727]
train loss: 7.129771  [89600/108727]
train loss: 3.378794  [92800/108727]
train loss: 6.614770  [96000/108727]
train loss: 3.035481  [99200/108727]
train loss: 10.467800  [102400/108727]
train loss: 4.837147  [105600/108727]
Avg validation loss: 5.877199
Epoch 3
-------------------------------
train loss: 4.484436  [    0/108727]
train loss: 3.279521  [ 3200/108727]
train loss: 2.986823  [ 6400/108727]
train loss: 3.332386  [ 9600/108727]
train loss: 6.450764  [12800/108727]
train loss: 6.078204  [16000/108727]
train loss: 4.226263  [19200/108727]
train loss: 2.586507  [22400/108727]
train loss: 3.146059  [25600/108727]
train loss: 3.200754  [28800/108727]
train loss: 4.609502  [32000/108727]
train loss: 6.097205  [35200/108727]
train loss: 2.189929  [38400/108727]
train loss: 5.997298  [41600/108727]
train loss: 3.482441  [44800/108727]
train loss: 5.225332  [48000/108727]
train loss: 3.483177  [51200/108727]
train loss: 3.531531  [54400/108727]
train loss: 3.108218  [57600/108727]
train loss: 3.401830  [60800/108727]
train loss: 4.224933  [64000/108727]
train loss: 2.053071  [67200/108727]
train loss: 3.409123  [70400/108727]
train loss: 8.884088  [73600/108727]
train loss: 2.659224  [76800/108727]
train loss: 3.166006  [80000/108727]
train loss: 3.971878  [83200/108727]
train loss: 3.834998  [86400/108727]
train loss: 3.252349  [89600/108727]
train loss: 4.318401  [92800/108727]
train loss: 2.823178  [96000/108727]
train loss: 5.150334  [99200/108727]
train loss: 8.219177  [102400/108727]
train loss: 3.609360  [105600/108727]
Avg validation loss: 3.992191
Epoch 4
-------------------------------
train loss: 4.451628  [    0/108727]
train loss: 2.287099  [ 3200/108727]
train loss: 3.104383  [ 6400/108727]
train loss: 2.560599  [ 9600/108727]
train loss: 2.433249  [12800/108727]
train loss: 2.145199  [16000/108727]
train loss: 4.182456  [19200/108727]
train loss: 2.890260  [22400/108727]
train loss: 3.538842  [25600/108727]
train loss: 6.457223  [28800/108727]
train loss: 3.220844  [32000/108727]
train loss: 5.318711  [35200/108727]
train loss: 4.865448  [38400/108727]
train loss: 2.533887  [41600/108727]
train loss: 3.492170  [44800/108727]
train loss: 4.935955  [48000/108727]
train loss: 2.841137  [51200/108727]
train loss: 4.107262  [54400/108727]
train loss: 3.340739  [57600/108727]
train loss: 2.125389  [60800/108727]
train loss: 2.044473  [64000/108727]
train loss: 3.386308  [67200/108727]
train loss: 3.720973  [70400/108727]
train loss: 2.688170  [73600/108727]
train loss: 7.163916  [76800/108727]
train loss: 2.287137  [80000/108727]
train loss: 1.816417  [83200/108727]
train loss: 3.106489  [86400/108727]
train loss: 3.259271  [89600/108727]
train loss: 2.390623  [92800/108727]
train loss: 2.939464  [96000/108727]
train loss: 2.894670  [99200/108727]
train loss: 2.657435  [102400/108727]
train loss: 3.111625  [105600/108727]
Avg validation loss: 3.055720
Epoch 5
-------------------------------
train loss: 2.274770  [    0/108727]
train loss: 1.500437  [ 3200/108727]
train loss: 2.695021  [ 6400/108727]
train loss: 3.399041  [ 9600/108727]
train loss: 3.372852  [12800/108727]
train loss: 2.890887  [16000/108727]
train loss: 2.474081  [19200/108727]
train loss: 2.040850  [22400/108727]
train loss: 4.379558  [25600/108727]
train loss: 1.944067  [28800/108727]
train loss: 4.203963  [32000/108727]
train loss: 2.015794  [35200/108727]
train loss: 2.655354  [38400/108727]
train loss: 1.406638  [41600/108727]
train loss: 2.269204  [44800/108727]
train loss: 2.307833  [48000/108727]
train loss: 2.938175  [51200/108727]
train loss: 3.842133  [54400/108727]
train loss: 3.101992  [57600/108727]
train loss: 3.037610  [60800/108727]
train loss: 2.991412  [64000/108727]
train loss: 2.749510  [67200/108727]
train loss: 4.135963  [70400/108727]
train loss: 3.543069  [73600/108727]
train loss: 3.005852  [76800/108727]
train loss: 3.812922  [80000/108727]
train loss: 2.760590  [83200/108727]
train loss: 2.044190  [86400/108727]
train loss: 3.161971  [89600/108727]
train loss: 3.860666  [92800/108727]
train loss: 2.100466  [96000/108727]
train loss: 2.452025  [99200/108727]
train loss: 4.144186  [102400/108727]
train loss: 1.935766  [105600/108727]
Avg validation loss: 2.494231
Epoch 6
-------------------------------
train loss: 4.304259  [    0/108727]
train loss: 10.529334  [ 3200/108727]
train loss: 2.424673  [ 6400/108727]
train loss: 1.973575  [ 9600/108727]
train loss: 1.466232  [12800/108727]
train loss: 3.464509  [16000/108727]
train loss: 2.648032  [19200/108727]
train loss: 1.648666  [22400/108727]
train loss: 1.905977  [25600/108727]
train loss: 2.319411  [28800/108727]
train loss: 1.491276  [32000/108727]
train loss: 2.751227  [35200/108727]
train loss: 3.544907  [38400/108727]
train loss: 2.620592  [41600/108727]
train loss: 5.168087  [44800/108727]
train loss: 1.660583  [48000/108727]
train loss: 2.304228  [51200/108727]
train loss: 2.033396  [54400/108727]
train loss: 2.427898  [57600/108727]
train loss: 2.666540  [60800/108727]
train loss: 1.855208  [64000/108727]
train loss: 1.635368  [67200/108727]
train loss: 2.607992  [70400/108727]
train loss: 5.382826  [73600/108727]
train loss: 4.445591  [76800/108727]
train loss: 1.451802  [80000/108727]
train loss: 1.517709  [83200/108727]
train loss: 4.187684  [86400/108727]
train loss: 2.982295  [89600/108727]
train loss: 2.441721  [92800/108727]
train loss: 2.004316  [96000/108727]
train loss: 2.050425  [99200/108727]
train loss: 4.471643  [102400/108727]
train loss: 3.136383  [105600/108727]
Avg validation loss: 2.308528
Epoch 7
-------------------------------
train loss: 1.680470  [    0/108727]
train loss: 3.307479  [ 3200/108727]
train loss: 2.361221  [ 6400/108727]
train loss: 1.582079  [ 9600/108727]
train loss: 2.633323  [12800/108727]
train loss: 1.597923  [16000/108727]
train loss: 3.388261  [19200/108727]
train loss: 1.693046  [22400/108727]
train loss: 3.265060  [25600/108727]
train loss: 6.414999  [28800/108727]
train loss: 4.627802  [32000/108727]
train loss: 2.156598  [35200/108727]
train loss: 2.565715  [38400/108727]
train loss: 1.447594  [41600/108727]
train loss: 1.473579  [44800/108727]
train loss: 2.737176  [48000/108727]
train loss: 2.025203  [51200/108727]
train loss: 1.948195  [54400/108727]
train loss: 1.256382  [57600/108727]
train loss: 1.236333  [60800/108727]
train loss: 2.612296  [64000/108727]
train loss: 2.159400  [67200/108727]
train loss: 2.742745  [70400/108727]
train loss: 1.519478  [73600/108727]
train loss: 2.397954  [76800/108727]
train loss: 1.581097  [80000/108727]
train loss: 1.278920  [83200/108727]
train loss: 1.519220  [86400/108727]
train loss: 2.479558  [89600/108727]
train loss: 2.119168  [92800/108727]
train loss: 1.648124  [96000/108727]
train loss: 4.943706  [99200/108727]
train loss: 1.783037  [102400/108727]
train loss: 1.835180  [105600/108727]
Avg validation loss: 2.054920
Epoch 8
-------------------------------
train loss: 2.950238  [    0/108727]
train loss: 2.128997  [ 3200/108727]
train loss: 3.048223  [ 6400/108727]
train loss: 2.272326  [ 9600/108727]
train loss: 1.599166  [12800/108727]
train loss: 2.805066  [16000/108727]
train loss: 3.933057  [19200/108727]
train loss: 3.138690  [22400/108727]
train loss: 2.020128  [25600/108727]
train loss: 1.738146  [28800/108727]
train loss: 2.236916  [32000/108727]
train loss: 1.616084  [35200/108727]
train loss: 2.304385  [38400/108727]
train loss: 2.478374  [41600/108727]
train loss: 1.863902  [44800/108727]
train loss: 1.504362  [48000/108727]
train loss: 3.082326  [51200/108727]
train loss: 1.841323  [54400/108727]
train loss: 1.929634  [57600/108727]
train loss: 1.575969  [60800/108727]
train loss: 2.667537  [64000/108727]
train loss: 1.975869  [67200/108727]
train loss: 1.918140  [70400/108727]
train loss: 4.483700  [73600/108727]
train loss: 1.122772  [76800/108727]
train loss: 1.750240  [80000/108727]
train loss: 1.903616  [83200/108727]
train loss: 2.030788  [86400/108727]
train loss: 2.017355  [89600/108727]
train loss: 1.639486  [92800/108727]
train loss: 2.105980  [96000/108727]
train loss: 1.708289  [99200/108727]
train loss: 2.343171  [102400/108727]
train loss: 3.347286  [105600/108727]
Avg validation loss: 2.398867
Epoch 9
-------------------------------
train loss: 2.117047  [    0/108727]
train loss: 2.498874  [ 3200/108727]
train loss: 2.167072  [ 6400/108727]
train loss: 1.707099  [ 9600/108727]
train loss: 2.133062  [12800/108727]
train loss: 3.019811  [16000/108727]
train loss: 1.657332  [19200/108727]
train loss: 1.623295  [22400/108727]
train loss: 1.359706  [25600/108727]
train loss: 1.724150  [28800/108727]
train loss: 2.361931  [32000/108727]
train loss: 2.103145  [35200/108727]
train loss: 3.406837  [38400/108727]
train loss: 1.949161  [41600/108727]
train loss: 1.859277  [44800/108727]
train loss: 2.857543  [48000/108727]
train loss: 1.614593  [51200/108727]
train loss: 1.434388  [54400/108727]
train loss: 1.457013  [57600/108727]
train loss: 2.207104  [60800/108727]
train loss: 1.140742  [64000/108727]
train loss: 1.325895  [67200/108727]
train loss: 1.999604  [70400/108727]
train loss: 1.153136  [73600/108727]
train loss: 2.444606  [76800/108727]
train loss: 2.140988  [80000/108727]
train loss: 1.923702  [83200/108727]
train loss: 1.997074  [86400/108727]
train loss: 1.408787  [89600/108727]
train loss: 2.304687  [92800/108727]
train loss: 1.576233  [96000/108727]
train loss: 1.751483  [99200/108727]
train loss: 1.726253  [102400/108727]
train loss: 1.246888  [105600/108727]
Avg validation loss: 2.505667
Epoch 10
-------------------------------
train loss: 2.224021  [    0/108727]
train loss: 1.473067  [ 3200/108727]
train loss: 1.211468  [ 6400/108727]
train loss: 1.311395  [ 9600/108727]
train loss: 1.240686  [12800/108727]
train loss: 1.740374  [16000/108727]
train loss: 1.424459  [19200/108727]
train loss: 1.226852  [22400/108727]
train loss: 2.051989  [25600/108727]
train loss: 1.503392  [28800/108727]
train loss: 2.115761  [32000/108727]
train loss: 1.419065  [35200/108727]
train loss: 2.173380  [38400/108727]
train loss: 1.035605  [41600/108727]
train loss: 1.328583  [44800/108727]
train loss: 2.317334  [48000/108727]
train loss: 2.244889  [51200/108727]
train loss: 3.651537  [54400/108727]
train loss: 1.889373  [57600/108727]
train loss: 3.032191  [60800/108727]
train loss: 2.192542  [64000/108727]
train loss: 1.352241  [67200/108727]
train loss: 1.877875  [70400/108727]
train loss: 2.266070  [73600/108727]
train loss: 1.799070  [76800/108727]
train loss: 1.682296  [80000/108727]
train loss: 1.437193  [83200/108727]
train loss: 1.733538  [86400/108727]
train loss: 2.073140  [89600/108727]
train loss: 3.580181  [92800/108727]
train loss: 1.313616  [96000/108727]
train loss: 1.927856  [99200/108727]
train loss: 1.633139  [102400/108727]
train loss: 1.548681  [105600/108727]
Avg validation loss: 1.638861
Epoch 11
-------------------------------
train loss: 1.564884  [    0/108727]
train loss: 2.379661  [ 3200/108727]
train loss: 0.960154  [ 6400/108727]
train loss: 2.219226  [ 9600/108727]
train loss: 0.946029  [12800/108727]
train loss: 1.690683  [16000/108727]
train loss: 3.240531  [19200/108727]
train loss: 2.968455  [22400/108727]
train loss: 1.731722  [25600/108727]
train loss: 1.582428  [28800/108727]
train loss: 1.073006  [32000/108727]
train loss: 1.473489  [35200/108727]
train loss: 2.069747  [38400/108727]
train loss: 0.982960  [41600/108727]
train loss: 1.994381  [44800/108727]
train loss: 1.285468  [48000/108727]
train loss: 2.552114  [51200/108727]
train loss: 1.878424  [54400/108727]
train loss: 1.289785  [57600/108727]
train loss: 1.308167  [60800/108727]
train loss: 1.574352  [64000/108727]
train loss: 2.418146  [67200/108727]
train loss: 2.371186  [70400/108727]
train loss: 1.290886  [73600/108727]
train loss: 1.125132  [76800/108727]
train loss: 1.463452  [80000/108727]
train loss: 1.538371  [83200/108727]
train loss: 2.548798  [86400/108727]
train loss: 2.604946  [89600/108727]
train loss: 2.186035  [92800/108727]
train loss: 1.522787  [96000/108727]
train loss: 1.317625  [99200/108727]
train loss: 2.116956  [102400/108727]
train loss: 0.937230  [105600/108727]
Avg validation loss: 1.466512
Epoch 12
-------------------------------
train loss: 1.720287  [    0/108727]
train loss: 1.876402  [ 3200/108727]
train loss: 1.593361  [ 6400/108727]
train loss: 0.885128  [ 9600/108727]
train loss: 1.031674  [12800/108727]
train loss: 1.795485  [16000/108727]
train loss: 1.672896  [19200/108727]
train loss: 2.439573  [22400/108727]
train loss: 1.457395  [25600/108727]
train loss: 1.291603  [28800/108727]
train loss: 1.269170  [32000/108727]
train loss: 1.416405  [35200/108727]
train loss: 2.247807  [38400/108727]
train loss: 0.960063  [41600/108727]
train loss: 1.459786  [44800/108727]
train loss: 1.551175  [48000/108727]
train loss: 1.139774  [51200/108727]
train loss: 1.886652  [54400/108727]
train loss: 1.092371  [57600/108727]
train loss: 1.191186  [60800/108727]
train loss: 1.822607  [64000/108727]
train loss: 2.048171  [67200/108727]
train loss: 2.811624  [70400/108727]
train loss: 1.354250  [73600/108727]
train loss: 1.897806  [76800/108727]
train loss: 1.780089  [80000/108727]
train loss: 1.270301  [83200/108727]
train loss: 1.381558  [86400/108727]
train loss: 1.939499  [89600/108727]
train loss: 1.436778  [92800/108727]
train loss: 1.401338  [96000/108727]
train loss: 1.367339  [99200/108727]
train loss: 2.056883  [102400/108727]
train loss: 1.830477  [105600/108727]
Avg validation loss: 1.717332
Epoch 13
-------------------------------
train loss: 3.367002  [    0/108727]
train loss: 1.847384  [ 3200/108727]
train loss: 1.414107  [ 6400/108727]
train loss: 3.012118  [ 9600/108727]
train loss: 1.233120  [12800/108727]
train loss: 0.947524  [16000/108727]
train loss: 1.141670  [19200/108727]
train loss: 1.484948  [22400/108727]
train loss: 1.982096  [25600/108727]
train loss: 1.385580  [28800/108727]
train loss: 1.046913  [32000/108727]
train loss: 1.294346  [35200/108727]
train loss: 1.152278  [38400/108727]
train loss: 0.757406  [41600/108727]
train loss: 4.042280  [44800/108727]
train loss: 1.816736  [48000/108727]
train loss: 1.418242  [51200/108727]
train loss: 0.975632  [54400/108727]
train loss: 1.116106  [57600/108727]
train loss: 1.869722  [60800/108727]
train loss: 0.856096  [64000/108727]
train loss: 0.790282  [67200/108727]
train loss: 1.227935  [70400/108727]
train loss: 1.260259  [73600/108727]
train loss: 4.255822  [76800/108727]
train loss: 1.250294  [80000/108727]
train loss: 2.126254  [83200/108727]
train loss: 1.948673  [86400/108727]
train loss: 2.401029  [89600/108727]
train loss: 2.758061  [92800/108727]
train loss: 1.125395  [96000/108727]
train loss: 1.065695  [99200/108727]
train loss: 1.276849  [102400/108727]
train loss: 0.994752  [105600/108727]
Avg validation loss: 1.469120
Epoch 14
-------------------------------
train loss: 1.192925  [    0/108727]
train loss: 0.798184  [ 3200/108727]
train loss: 1.040955  [ 6400/108727]
train loss: 2.061374  [ 9600/108727]
train loss: 1.175453  [12800/108727]
train loss: 1.907475  [16000/108727]
train loss: 1.235061  [19200/108727]
train loss: 0.909215  [22400/108727]
train loss: 1.193513  [25600/108727]
train loss: 1.421368  [28800/108727]
train loss: 2.302043  [32000/108727]
train loss: 1.394373  [35200/108727]
train loss: 1.234446  [38400/108727]
train loss: 1.212400  [41600/108727]
train loss: 2.033590  [44800/108727]
train loss: 1.373205  [48000/108727]
train loss: 2.557185  [51200/108727]
train loss: 1.039838  [54400/108727]
train loss: 1.767132  [57600/108727]
train loss: 3.716209  [60800/108727]
train loss: 1.370688  [64000/108727]
train loss: 1.280082  [67200/108727]
train loss: 0.555547  [70400/108727]
train loss: 1.360973  [73600/108727]
train loss: 1.295761  [76800/108727]
train loss: 1.045767  [80000/108727]
train loss: 1.752555  [83200/108727]
train loss: 0.944175  [86400/108727]
train loss: 1.627572  [89600/108727]
train loss: 1.256835  [92800/108727]
train loss: 2.357882  [96000/108727]
train loss: 1.606139  [99200/108727]
train loss: 1.420528  [102400/108727]
train loss: 2.772707  [105600/108727]
Avg validation loss: 1.497403
Epoch 15
-------------------------------
train loss: 1.466794  [    0/108727]
train loss: 4.975033  [ 3200/108727]
train loss: 1.123356  [ 6400/108727]
train loss: 1.515949  [ 9600/108727]
train loss: 2.530061  [12800/108727]
train loss: 1.177289  [16000/108727]
train loss: 1.598605  [19200/108727]
train loss: 1.716535  [22400/108727]
train loss: 1.325351  [25600/108727]
train loss: 1.888228  [28800/108727]
train loss: 0.817204  [32000/108727]
train loss: 1.967566  [35200/108727]
train loss: 1.350484  [38400/108727]
train loss: 1.420905  [41600/108727]
train loss: 0.944416  [44800/108727]
train loss: 1.956313  [48000/108727]
train loss: 2.100423  [51200/108727]
train loss: 1.767028  [54400/108727]
train loss: 1.115923  [57600/108727]
train loss: 1.348418  [60800/108727]
train loss: 1.325534  [64000/108727]
train loss: 1.171400  [67200/108727]
train loss: 1.020007  [70400/108727]
train loss: 1.260510  [73600/108727]
train loss: 1.133398  [76800/108727]
train loss: 1.472877  [80000/108727]
train loss: 1.201111  [83200/108727]
train loss: 1.170906  [86400/108727]
train loss: 1.897446  [89600/108727]
train loss: 1.535888  [92800/108727]
train loss: 1.119071  [96000/108727]
train loss: 1.081146  [99200/108727]
train loss: 1.310789  [102400/108727]
train loss: 1.212164  [105600/108727]
Avg validation loss: 1.705801
Epoch 16
-------------------------------
train loss: 1.154139  [    0/108727]
train loss: 1.620916  [ 3200/108727]
train loss: 0.982594  [ 6400/108727]
train loss: 1.023388  [ 9600/108727]
train loss: 1.344327  [12800/108727]
train loss: 1.492819  [16000/108727]
train loss: 1.202409  [19200/108727]
train loss: 1.491798  [22400/108727]
train loss: 1.849103  [25600/108727]
train loss: 0.986367  [28800/108727]
train loss: 1.860045  [32000/108727]
train loss: 1.872221  [35200/108727]
train loss: 1.349226  [38400/108727]
train loss: 0.984669  [41600/108727]
train loss: 1.372394  [44800/108727]
train loss: 1.438580  [48000/108727]
train loss: 0.671070  [51200/108727]
train loss: 1.156597  [54400/108727]
train loss: 1.277086  [57600/108727]
train loss: 1.401754  [60800/108727]
train loss: 1.002666  [64000/108727]
train loss: 1.026180  [67200/108727]
train loss: 1.202358  [70400/108727]
train loss: 1.195628  [73600/108727]
train loss: 1.058209  [76800/108727]
train loss: 1.522771  [80000/108727]
train loss: 1.405132  [83200/108727]
train loss: 1.267213  [86400/108727]
train loss: 1.358199  [89600/108727]
train loss: 1.321923  [92800/108727]
train loss: 3.182396  [96000/108727]
train loss: 1.404547  [99200/108727]
train loss: 1.302535  [102400/108727]
train loss: 0.961033  [105600/108727]
Avg validation loss: 1.789300
Epoch 17
-------------------------------
train loss: 1.371578  [    0/108727]
train loss: 0.796073  [ 3200/108727]
train loss: 1.336782  [ 6400/108727]
train loss: 1.421940  [ 9600/108727]
train loss: 0.974441  [12800/108727]
train loss: 1.188853  [16000/108727]
train loss: 1.503128  [19200/108727]
train loss: 0.950311  [22400/108727]
train loss: 1.223652  [25600/108727]
train loss: 1.085495  [28800/108727]
train loss: 1.106329  [32000/108727]
train loss: 2.372589  [35200/108727]
train loss: 0.775544  [38400/108727]
train loss: 1.130548  [41600/108727]
train loss: 0.776781  [44800/108727]
train loss: 1.824722  [48000/108727]
train loss: 1.421576  [51200/108727]
train loss: 0.820464  [54400/108727]
train loss: 2.073804  [57600/108727]
train loss: 1.075127  [60800/108727]
train loss: 1.161906  [64000/108727]
train loss: 0.784246  [67200/108727]
train loss: 1.099312  [70400/108727]
train loss: 1.020969  [73600/108727]
train loss: 1.586461  [76800/108727]
train loss: 1.492574  [80000/108727]
train loss: 1.128218  [83200/108727]
train loss: 1.234365  [86400/108727]
train loss: 1.093025  [89600/108727]
train loss: 0.912461  [92800/108727]
train loss: 1.804426  [96000/108727]
train loss: 1.719413  [99200/108727]
train loss: 1.158944  [102400/108727]
train loss: 1.343872  [105600/108727]
Avg validation loss: 1.641183
Epoch 18
-------------------------------
train loss: 1.821504  [    0/108727]
train loss: 1.725462  [ 3200/108727]
train loss: 1.188714  [ 6400/108727]
train loss: 1.522021  [ 9600/108727]
train loss: 1.633520  [12800/108727]
train loss: 1.336481  [16000/108727]
train loss: 0.959882  [19200/108727]
train loss: 1.308793  [22400/108727]
train loss: 0.942529  [25600/108727]
train loss: 2.700598  [28800/108727]
train loss: 0.560145  [32000/108727]
train loss: 1.718642  [35200/108727]
train loss: 1.512106  [38400/108727]
train loss: 1.598068  [41600/108727]
train loss: 1.328323  [44800/108727]
train loss: 0.692605  [48000/108727]
train loss: 1.062217  [51200/108727]
train loss: 0.658025  [54400/108727]
train loss: 0.833216  [57600/108727]
train loss: 1.263136  [60800/108727]
train loss: 0.995005  [64000/108727]
train loss: 1.408717  [67200/108727]
train loss: 1.142699  [70400/108727]
train loss: 1.782219  [73600/108727]
train loss: 1.809577  [76800/108727]
train loss: 2.437899  [80000/108727]
train loss: 1.045621  [83200/108727]
train loss: 1.239651  [86400/108727]
train loss: 1.320889  [89600/108727]
train loss: 1.067527  [92800/108727]
train loss: 1.152761  [96000/108727]
train loss: 0.686198  [99200/108727]
train loss: 1.134500  [102400/108727]
train loss: 0.992478  [105600/108727]
Avg validation loss: 1.096108
Epoch 19
-------------------------------
train loss: 1.289968  [    0/108727]
train loss: 1.843053  [ 3200/108727]
train loss: 0.836914  [ 6400/108727]
train loss: 0.620403  [ 9600/108727]
train loss: 2.355317  [12800/108727]
train loss: 1.219132  [16000/108727]
train loss: 0.885170  [19200/108727]
train loss: 1.491285  [22400/108727]
train loss: 1.284762  [25600/108727]
train loss: 1.126217  [28800/108727]
train loss: 1.182495  [32000/108727]
train loss: 1.785747  [35200/108727]
train loss: 0.951282  [38400/108727]
train loss: 1.183423  [41600/108727]
train loss: 1.582202  [44800/108727]
train loss: 0.888866  [48000/108727]
train loss: 1.462169  [51200/108727]
train loss: 1.791263  [54400/108727]
train loss: 1.657879  [57600/108727]
train loss: 1.656963  [60800/108727]
train loss: 0.854998  [64000/108727]
train loss: 3.067451  [67200/108727]
train loss: 1.429324  [70400/108727]
train loss: 1.176825  [73600/108727]
train loss: 0.852445  [76800/108727]
train loss: 1.470716  [80000/108727]
train loss: 1.340611  [83200/108727]
train loss: 1.905820  [86400/108727]
train loss: 1.372679  [89600/108727]
train loss: 1.380965  [92800/108727]
train loss: 1.977981  [96000/108727]
train loss: 0.864152  [99200/108727]
train loss: 1.276642  [102400/108727]
train loss: 2.888008  [105600/108727]
Avg validation loss: 1.257447
Epoch 20
-------------------------------
train loss: 1.637922  [    0/108727]
train loss: 1.249055  [ 3200/108727]
train loss: 1.169162  [ 6400/108727]
train loss: 1.136338  [ 9600/108727]
train loss: 0.962988  [12800/108727]
train loss: 1.234825  [16000/108727]
train loss: 0.688162  [19200/108727]
train loss: 1.039285  [22400/108727]
train loss: 1.174507  [25600/108727]
train loss: 1.067551  [28800/108727]
train loss: 1.391978  [32000/108727]
train loss: 0.955863  [35200/108727]
train loss: 1.675953  [38400/108727]
train loss: 0.873454  [41600/108727]
train loss: 0.847918  [44800/108727]
train loss: 0.969543  [48000/108727]
train loss: 1.013768  [51200/108727]
train loss: 1.063549  [54400/108727]
train loss: 1.550719  [57600/108727]
train loss: 1.117679  [60800/108727]
train loss: 2.191825  [64000/108727]
train loss: 0.846450  [67200/108727]
train loss: 1.196136  [70400/108727]
train loss: 0.966122  [73600/108727]
train loss: 0.726590  [76800/108727]
train loss: 0.909574  [80000/108727]
train loss: 1.155999  [83200/108727]
train loss: 1.500024  [86400/108727]
train loss: 1.295547  [89600/108727]
train loss: 2.183914  [92800/108727]
train loss: 1.055910  [96000/108727]
train loss: 1.068700  [99200/108727]
train loss: 1.011063  [102400/108727]
train loss: 1.563547  [105600/108727]
Avg validation loss: 1.381807
Done!